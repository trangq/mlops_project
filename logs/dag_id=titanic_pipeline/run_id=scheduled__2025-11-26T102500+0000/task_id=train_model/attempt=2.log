[2025-11-26T10:31:10.310+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-11-26T10:31:10.340+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: titanic_pipeline.train_model scheduled__2025-11-26T10:25:00+00:00 [queued]>
[2025-11-26T10:31:10.349+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: titanic_pipeline.train_model scheduled__2025-11-26T10:25:00+00:00 [queued]>
[2025-11-26T10:31:10.350+0000] {taskinstance.py:2306} INFO - Starting attempt 2 of 2
[2025-11-26T10:31:10.365+0000] {taskinstance.py:2330} INFO - Executing <Task(BashOperator): train_model> on 2025-11-26 10:25:00+00:00
[2025-11-26T10:31:10.369+0000] {standard_task_runner.py:63} INFO - Started process 329 to run task
[2025-11-26T10:31:10.372+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'titanic_pipeline', 'train_model', 'scheduled__2025-11-26T10:25:00+00:00', '--job-id', '25', '--raw', '--subdir', 'DAGS_FOLDER/training_pipeline_dag.py', '--cfg-path', '/tmp/tmpbrxznnoq']
[2025-11-26T10:31:10.373+0000] {standard_task_runner.py:91} INFO - Job 25: Subtask train_model
[2025-11-26T10:31:10.388+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/***/settings.py:195: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  SQL_ALCHEMY_CONN = conf.get("database", "SQL_ALCHEMY_CONN")

[2025-11-26T10:31:10.458+0000] {task_command.py:426} INFO - Running <TaskInstance: titanic_pipeline.train_model scheduled__2025-11-26T10:25:00+00:00 [running]> on host 86765dc6c081
[2025-11-26T10:31:10.524+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='titanic_pipeline' AIRFLOW_CTX_TASK_ID='train_model' AIRFLOW_CTX_EXECUTION_DATE='2025-11-26T10:25:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-11-26T10:25:00+00:00'
[2025-11-26T10:31:10.525+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-11-26T10:31:10.553+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-11-26T10:31:10.556+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'python /opt/***/scripts/train_model.py /opt/***/data/cleaned_data.csv']
[2025-11-26T10:31:10.570+0000] {subprocess.py:86} INFO - Output:
[2025-11-26T10:31:17.254+0000] {subprocess.py:93} INFO - 2025/11/26 10:31:17 INFO mlflow.tracking.fluent: Experiment with name 'TitanicClassifier_Experiment' does not exist. Creating a new experiment.
[2025-11-26T10:31:18.032+0000] {subprocess.py:93} INFO - 2025/11/26 10:31:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
[2025-11-26T10:31:18.681+0000] {subprocess.py:93} INFO - /home/***/.local/lib/python3.10/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.
[2025-11-26T10:31:18.686+0000] {subprocess.py:93} INFO -   warnings.warn(
[2025-11-26T10:31:18.699+0000] {subprocess.py:93} INFO - /home/***/.local/lib/python3.10/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.
[2025-11-26T10:31:18.700+0000] {subprocess.py:93} INFO -   warnings.warn(
[2025-11-26T10:32:11.539+0000] {subprocess.py:93} INFO - Loading processed data from: /opt/***/data/cleaned_data.csv
[2025-11-26T10:32:11.547+0000] {subprocess.py:93} INFO - 
[2025-11-26T10:32:11.547+0000] {subprocess.py:93} INFO - === Logging model to MLflow ===
[2025-11-26T10:32:11.548+0000] {subprocess.py:93} INFO - üèÉ View run dashing-shrimp-840 at: http://mlflow-server:5000/#/experiments/1/runs/1b5999bf65334050bacd7c9a974d73cf
[2025-11-26T10:32:11.548+0000] {subprocess.py:93} INFO - üß™ View experiment at: http://mlflow-server:5000/#/experiments/1
[2025-11-26T10:32:11.549+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-11-26T10:32:11.549+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/boto3/s3/transfer.py", line 371, in upload_file
[2025-11-26T10:32:11.550+0000] {subprocess.py:93} INFO -     future.result()
[2025-11-26T10:32:11.550+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/s3transfer/futures.py", line 103, in result
[2025-11-26T10:32:11.551+0000] {subprocess.py:93} INFO -     return self._coordinator.result()
[2025-11-26T10:32:11.551+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/s3transfer/futures.py", line 266, in result
[2025-11-26T10:32:11.551+0000] {subprocess.py:93} INFO -     raise self._exception
[2025-11-26T10:32:11.552+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/s3transfer/tasks.py", line 139, in __call__
[2025-11-26T10:32:11.552+0000] {subprocess.py:93} INFO -     return self._execute_main(kwargs)
[2025-11-26T10:32:11.553+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/s3transfer/tasks.py", line 162, in _execute_main
[2025-11-26T10:32:11.553+0000] {subprocess.py:93} INFO -     return_value = self._main(**kwargs)
[2025-11-26T10:32:11.554+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/s3transfer/upload.py", line 764, in _main
[2025-11-26T10:32:11.554+0000] {subprocess.py:93} INFO -     client.put_object(Bucket=bucket, Key=key, Body=body, **extra_args)
[2025-11-26T10:32:11.555+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/botocore/client.py", line 565, in _api_call
[2025-11-26T10:32:11.555+0000] {subprocess.py:93} INFO -     return self._make_api_call(operation_name, kwargs)
[2025-11-26T10:32:11.556+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/botocore/client.py", line 1021, in _make_api_call
[2025-11-26T10:32:11.556+0000] {subprocess.py:93} INFO -     raise error_class(parsed_response, operation_name)
[2025-11-26T10:32:11.557+0000] {subprocess.py:93} INFO - botocore.errorfactory.NoSuchBucket: An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist
[2025-11-26T10:32:11.557+0000] {subprocess.py:93} INFO - 
[2025-11-26T10:32:11.558+0000] {subprocess.py:93} INFO - During handling of the above exception, another exception occurred:
[2025-11-26T10:32:11.558+0000] {subprocess.py:93} INFO - 
[2025-11-26T10:32:11.558+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-11-26T10:32:11.559+0000] {subprocess.py:93} INFO -   File "/opt/***/scripts/train_model.py", line 90, in <module>
[2025-11-26T10:32:11.559+0000] {subprocess.py:93} INFO -     train(sys.argv[1])
[2025-11-26T10:32:11.560+0000] {subprocess.py:93} INFO -   File "/opt/***/scripts/train_model.py", line 57, in train
[2025-11-26T10:32:11.560+0000] {subprocess.py:93} INFO -     model_info = mlflow.sklearn.log_model(
[2025-11-26T10:32:11.561+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/mlflow/sklearn/__init__.py", line 426, in log_model
[2025-11-26T10:32:11.561+0000] {subprocess.py:93} INFO -     return Model.log(
[2025-11-26T10:32:11.562+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/mlflow/models/model.py", line 1297, in log
[2025-11-26T10:32:11.562+0000] {subprocess.py:93} INFO -     client.log_model_artifacts(model.model_id, local_path)
[2025-11-26T10:32:11.563+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/mlflow/tracking/client.py", line 5643, in log_model_artifacts
[2025-11-26T10:32:11.563+0000] {subprocess.py:93} INFO -     return self._tracking_client.log_model_artifacts(model_id, local_dir)
[2025-11-26T10:32:11.563+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py", line 911, in log_model_artifacts
[2025-11-26T10:32:11.564+0000] {subprocess.py:93} INFO -     self._get_artifact_repo(model_id, resource="logged_model").log_artifacts(local_dir)
[2025-11-26T10:32:11.564+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/mlflow/store/artifact/s3_artifact_repo.py", line 299, in log_artifacts
[2025-11-26T10:32:11.565+0000] {subprocess.py:93} INFO -     self._upload_file(
[2025-11-26T10:32:11.565+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/mlflow/store/artifact/s3_artifact_repo.py", line 247, in _upload_file
[2025-11-26T10:32:11.566+0000] {subprocess.py:93} INFO -     s3_client.upload_file(Filename=local_file, Bucket=bucket, Key=key, ExtraArgs=extra_args)
[2025-11-26T10:32:11.566+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/boto3/s3/inject.py", line 145, in upload_file
[2025-11-26T10:32:11.567+0000] {subprocess.py:93} INFO -     return transfer.upload_file(
[2025-11-26T10:32:11.567+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.10/site-packages/boto3/s3/transfer.py", line 377, in upload_file
[2025-11-26T10:32:11.567+0000] {subprocess.py:93} INFO -     raise S3UploadFailedError(
[2025-11-26T10:32:11.568+0000] {subprocess.py:93} INFO - boto3.exceptions.S3UploadFailedError: Failed to upload /tmp/tmpiw7vykz3/model/python_env.yaml to mlflow-artifacts/1/models/m-e3fd85473a054ff6939bd92ae3d23a34/artifacts/python_env.yaml: An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist
[2025-11-26T10:32:12.467+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-11-26T10:32:12.482+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-11-26T10:32:12.556+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 243, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-11-26T10:32:12.567+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=titanic_pipeline, task_id=train_model, run_id=scheduled__2025-11-26T10:25:00+00:00, execution_date=20251126T102500, start_date=20251126T103110, end_date=20251126T103212
[2025-11-26T10:32:12.596+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 25 for task train_model (Bash command failed. The command returned a non-zero exit code 1.; 329)
[2025-11-26T10:32:12.614+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-11-26T10:32:12.641+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-11-26T10:32:12.646+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
